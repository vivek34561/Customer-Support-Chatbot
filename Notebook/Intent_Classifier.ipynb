{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bf57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539b0af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flags                                        instruction category  \\\n",
       "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "\n",
       "         intent                                           response  \n",
       "0  cancel_order  I've understood you have a question regarding ...  \n",
       "1  cancel_order  I've been informed that you have a question ab...  \n",
       "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3  cancel_order  I understood that you need assistance with can...  \n",
       "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (26872, 5)\n",
      "\n",
      "Column names: ['flags', 'instruction', 'category', 'intent', 'response']\n",
      "\n",
      "Data types:\n",
      "flags          str\n",
      "instruction    str\n",
      "category       str\n",
      "intent         str\n",
      "response       str\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "flags          0\n",
      "instruction    0\n",
      "category       0\n",
      "intent         0\n",
      "response       0\n",
      "dtype: int64\n",
      "\n",
      "Number of unique intents: 27\n",
      "\n",
      "Intent distribution:\n",
      "intent\n",
      "check_invoice               1000\n",
      "complaint                   1000\n",
      "contact_customer_service    1000\n",
      "edit_account                1000\n",
      "switch_account              1000\n",
      "check_payment_methods        999\n",
      "contact_human_agent          999\n",
      "delivery_period              999\n",
      "get_invoice                  999\n",
      "newsletter_subscription      999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check dataset info\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nNumber of unique intents:\", df['intent'].nunique())\n",
    "print(\"\\nIntent distribution:\")\n",
    "print(df['intent'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b3ce9",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b87a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after cleaning: (26872, 6)\n",
      "\n",
      "Sample cleaned instructions:\n",
      "                                         instruction  \\\n",
      "0   question about cancelling order {{Order Number}}   \n",
      "1  i have a question about cancelling oorder {{Or...   \n",
      "2    i need help cancelling puchase {{Order Number}}   \n",
      "3         I need to cancel purchase {{Order Number}}   \n",
      "4  I cannot afford this order, cancel purchase {{...   \n",
      "5     can you help me cancel order {{Order Number}}?   \n",
      "6  I can no longer afford order {{Order Number}},...   \n",
      "7    I am trying to cancel purchase {{Order Number}}   \n",
      "8     I have got to cancel purchase {{Order Number}}   \n",
      "9    i need help canceling purchase {{Order Number}}   \n",
      "\n",
      "                             instruction_clean        intent  \n",
      "0              question about cancelling order  cancel_order  \n",
      "1    i have a question about cancelling oorder  cancel_order  \n",
      "2               i need help cancelling puchase  cancel_order  \n",
      "3                    i need to cancel purchase  cancel_order  \n",
      "4  i cannot afford this order, cancel purchase  cancel_order  \n",
      "5               can you help me cancel order ?  cancel_order  \n",
      "6     i can no longer afford order , cancel it  cancel_order  \n",
      "7               i am trying to cancel purchase  cancel_order  \n",
      "8                i have got to cancel purchase  cancel_order  \n",
      "9               i need help canceling purchase  cancel_order  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove placeholders like {{Order Number}}, {{Invoice Number}}, etc.\n",
    "df_clean['instruction_clean'] = df_clean['instruction'].apply(\n",
    "    lambda x: re.sub(r'\\{\\{.*?\\}\\}', '', x)\n",
    ")\n",
    "\n",
    "# Convert to lowercase\n",
    "df_clean['instruction_clean'] = df_clean['instruction_clean'].str.lower()\n",
    "\n",
    "# Remove extra whitespaces\n",
    "df_clean['instruction_clean'] = df_clean['instruction_clean'].str.strip()\n",
    "df_clean['instruction_clean'] = df_clean['instruction_clean'].apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', x)\n",
    ")\n",
    "\n",
    "# Remove any rows with empty instructions after cleaning\n",
    "df_clean = df_clean[df_clean['instruction_clean'].str.len() > 0]\n",
    "\n",
    "print(\"Dataset shape after cleaning:\", df_clean.shape)\n",
    "print(\"\\nSample cleaned instructions:\")\n",
    "print(df_clean[['instruction', 'instruction_clean', 'intent']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b426df",
   "metadata": {},
   "source": [
    "## Intent Classification Model using NLP + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe2d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['scikit-learn', 'nltk']\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941ec778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c3a3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 21497\n",
      "Testing set size: 5375\n",
      "\n",
      "Class distribution in training set:\n",
      "intent\n",
      "check_invoice               800\n",
      "contact_customer_service    800\n",
      "switch_account              800\n",
      "complaint                   800\n",
      "edit_account                800\n",
      "payment_issue               799\n",
      "delivery_period             799\n",
      "contact_human_agent         799\n",
      "get_invoice                 799\n",
      "check_payment_methods       799\n",
      "registration_problems       799\n",
      "newsletter_subscription     799\n",
      "track_refund                798\n",
      "cancel_order                798\n",
      "place_order                 798\n",
      "check_refund_policy         798\n",
      "get_refund                  798\n",
      "review                      798\n",
      "set_up_shipping_address     798\n",
      "change_order                798\n",
      "create_account              798\n",
      "track_order                 796\n",
      "delivery_options            796\n",
      "delete_account              796\n",
      "recover_password            796\n",
      "change_shipping_address     778\n",
      "check_cancellation_fee      760\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and labels\n",
    "X = df_clean['instruction_clean']\n",
    "y = df_clean['intent']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed00d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorization completed!\n",
      "Training data shape: (21497, 5000)\n",
      "Testing data shape: (5375, 5000)\n",
      "Number of features: 5000\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF Vectorizer\n",
    "# TF-IDF converts text to numerical features\n",
    "# - removes english stopwords (common words like 'the', 'is', 'and')\n",
    "# - uses unigrams and bigrams (1 and 2 word phrases)\n",
    "# - limits to top 5000 features\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    min_df=2,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "# Transform training and testing data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF Vectorization completed!\")\n",
    "print(f\"Training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing data shape: {X_test_tfidf.shape}\")\n",
    "print(f\"Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbad7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "\n",
    "logistic_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "logistic_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f23165",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b36855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9769 (97.69%)\n",
      "Training Accuracy: 0.9860 (98.60%)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = logistic_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Get training accuracy\n",
    "y_train_pred = logistic_model.predict(X_train_tfidf)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069522bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "check_invoice               1000\n",
       "complaint                   1000\n",
       "contact_customer_service    1000\n",
       "edit_account                1000\n",
       "switch_account              1000\n",
       "check_payment_methods        999\n",
       "contact_human_agent          999\n",
       "delivery_period              999\n",
       "get_invoice                  999\n",
       "newsletter_subscription      999\n",
       "payment_issue                999\n",
       "registration_problems        999\n",
       "cancel_order                 998\n",
       "place_order                  998\n",
       "track_refund                 998\n",
       "change_order                 997\n",
       "check_refund_policy          997\n",
       "create_account               997\n",
       "get_refund                   997\n",
       "review                       997\n",
       "set_up_shipping_address      997\n",
       "delete_account               995\n",
       "delivery_options             995\n",
       "recover_password             995\n",
       "track_order                  995\n",
       "change_shipping_address      973\n",
       "check_cancellation_fee       950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab293396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "================================================================================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "            cancel_order       0.99      0.98      0.99       200\n",
      "            change_order       0.96      0.94      0.95       199\n",
      " change_shipping_address       0.99      1.00      0.99       195\n",
      "  check_cancellation_fee       1.00      1.00      1.00       190\n",
      "           check_invoice       0.82      0.86      0.84       200\n",
      "   check_payment_methods       1.00      1.00      1.00       200\n",
      "     check_refund_policy       1.00      0.99      1.00       199\n",
      "               complaint       1.00      1.00      1.00       200\n",
      "contact_customer_service       1.00      0.98      0.99       200\n",
      "     contact_human_agent       0.99      0.99      0.99       200\n",
      "          create_account       0.99      0.97      0.98       199\n",
      "          delete_account       0.94      0.99      0.97       199\n",
      "        delivery_options       0.92      1.00      0.96       199\n",
      "         delivery_period       1.00      0.99      1.00       200\n",
      "            edit_account       0.98      1.00      0.99       200\n",
      "             get_invoice       0.85      0.82      0.84       200\n",
      "              get_refund       0.99      1.00      1.00       199\n",
      " newsletter_subscription       1.00      0.99      0.99       200\n",
      "           payment_issue       1.00      0.98      0.99       200\n",
      "             place_order       0.99      0.97      0.98       200\n",
      "        recover_password       0.99      1.00      1.00       199\n",
      "   registration_problems       0.98      0.99      0.99       200\n",
      "                  review       1.00      1.00      1.00       199\n",
      " set_up_shipping_address       1.00      0.99      0.99       199\n",
      "          switch_account       0.99      0.96      0.98       200\n",
      "             track_order       1.00      0.94      0.97       199\n",
      "            track_refund       1.00      1.00      1.00       200\n",
      "\n",
      "                accuracy                           0.98      5375\n",
      "               macro avg       0.98      0.98      0.98      5375\n",
      "            weighted avg       0.98      0.98      0.98      5375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred, target_names=logistic_model.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c3822",
   "metadata": {},
   "source": [
    "## Test the Model with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text):\n",
    "    \"\"\"\n",
    "    Predict the intent of a given text\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to classify\n",
    "        \n",
    "    Returns:\n",
    "        Predicted intent and confidence scores\n",
    "    \"\"\"\n",
    "    # Clean the text (same as training data)\n",
    "    text_clean = re.sub(r'\\{\\{.*?\\}\\}', '', text)\n",
    "    text_clean = text_clean.lower().strip()\n",
    "    text_clean = re.sub(r'\\s+', ' ', text_clean)\n",
    "    \n",
    "    # Transform using TF-IDF\n",
    "    text_tfidf = tfidf_vectorizer.transform([text_clean])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = logistic_model.predict(text_tfidf)[0]\n",
    "    probabilities = logistic_model.predict_proba(text_tfidf)[0]\n",
    "    \n",
    "    # Get top 3 predictions with probabilities\n",
    "    top_indices = probabilities.argsort()[-3:][::-1]\n",
    "    top_intents = [(logistic_model.classes_[i], probabilities[i]) for i in top_indices]\n",
    "    \n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Cleaned: {text_clean}\")\n",
    "    print(f\"\\nPredicted Intent: {prediction}\")\n",
    "    print(f\"Confidence: {max(probabilities):.4f}\")\n",
    "    print(f\"\\nTop 3 predictions:\")\n",
    "    for intent, prob in top_intents:\n",
    "        print(f\"  - {intent}: {prob:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31ef754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Intent Classifier with Sample Queries\n",
      "================================================================================\n",
      "Input: I want to cancel my order\n",
      "Cleaned: i want to cancel my order\n",
      "\n",
      "Predicted Intent: cancel_order\n",
      "Confidence: 0.9439\n",
      "\n",
      "Top 3 predictions:\n",
      "  - cancel_order: 0.9439\n",
      "  - delivery_options: 0.0091\n",
      "  - delete_account: 0.0077\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: How can I track my package?\n",
      "Cleaned: how can i track my package?\n",
      "\n",
      "Predicted Intent: track_refund\n",
      "Confidence: 0.3129\n",
      "\n",
      "Top 3 predictions:\n",
      "  - track_refund: 0.3129\n",
      "  - track_order: 0.1774\n",
      "  - delivery_period: 0.0959\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I need help setting up my account\n",
      "Cleaned: i need help setting up my account\n",
      "\n",
      "Predicted Intent: delete_account\n",
      "Confidence: 0.1686\n",
      "\n",
      "Top 3 predictions:\n",
      "  - delete_account: 0.1686\n",
      "  - switch_account: 0.1349\n",
      "  - create_account: 0.1220\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: What are the delivery options available?\n",
      "Cleaned: what are the delivery options available?\n",
      "\n",
      "Predicted Intent: delivery_options\n",
      "Confidence: 0.9393\n",
      "\n",
      "Top 3 predictions:\n",
      "  - delivery_options: 0.9393\n",
      "  - check_payment_methods: 0.0156\n",
      "  - set_up_shipping_address: 0.0043\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I forgot my password, please help\n",
      "Cleaned: i forgot my password, please help\n",
      "\n",
      "Predicted Intent: recover_password\n",
      "Confidence: 0.4773\n",
      "\n",
      "Top 3 predictions:\n",
      "  - recover_password: 0.4773\n",
      "  - get_invoice: 0.0390\n",
      "  - change_order: 0.0375\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: Can you send me my invoice?\n",
      "Cleaned: can you send me my invoice?\n",
      "\n",
      "Predicted Intent: get_invoice\n",
      "Confidence: 0.8222\n",
      "\n",
      "Top 3 predictions:\n",
      "  - get_invoice: 0.8222\n",
      "  - check_invoice: 0.0459\n",
      "  - review: 0.0242\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I want to change my shipping address\n",
      "Cleaned: i want to change my shipping address\n",
      "\n",
      "Predicted Intent: change_shipping_address\n",
      "Confidence: 0.8903\n",
      "\n",
      "Top 3 predictions:\n",
      "  - change_shipping_address: 0.8903\n",
      "  - set_up_shipping_address: 0.0598\n",
      "  - switch_account: 0.0100\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: How do I get a refund?\n",
      "Cleaned: how do i get a refund?\n",
      "\n",
      "Predicted Intent: get_refund\n",
      "Confidence: 0.6638\n",
      "\n",
      "Top 3 predictions:\n",
      "  - get_refund: 0.6638\n",
      "  - track_refund: 0.2740\n",
      "  - check_refund_policy: 0.0364\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample customer queries\n",
    "test_queries = [\n",
    "    \"I want to cancel my order\",\n",
    "    \"How can I track my package?\",\n",
    "    \"I need help setting up my account\",\n",
    "    \"What are the delivery options available?\",\n",
    "    \"I forgot my password, please help\",\n",
    "    \"Can you send me my invoice?\",\n",
    "    \"I want to change my shipping address\",\n",
    "    \"How do I get a refund?\"\n",
    "]\n",
    "\n",
    "print(\"Testing Intent Classifier with Sample Queries\")\n",
    "print(\"=\" * 80)\n",
    "for query in test_queries:\n",
    "    predict_intent(query)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c11f6",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "### Key Achievements:\n",
    "1. **Data Cleaning**: Successfully cleaned 26,872 customer support queries by:\n",
    "   - Removing placeholders ({{Order Number}}, etc.)\n",
    "   - Converting to lowercase\n",
    "   - Removing extra whitespaces\n",
    "\n",
    "2. **Feature Engineering**: Used TF-IDF Vectorization with:\n",
    "   - 5000 features\n",
    "   - Unigrams and bigrams (1-2 word phrases)\n",
    "   - English stopwords removed\n",
    "\n",
    "3. **Model Performance**:\n",
    "   - **Test Accuracy: 97.69%**\n",
    "   - **Training Accuracy: 98.60%**\n",
    "   - Successfully classifies 27 different customer intents\n",
    "\n",
    "4. **Model Components**:\n",
    "   - **NLP Technique**: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "   - **Classifier**: Logistic Regression\n",
    "   - **Dataset**: Bitext Customer Support Dataset (26,872 examples)\n",
    "\n",
    "### Use Case:\n",
    "This model can automatically classify customer support queries into 27 different intents, enabling:\n",
    "- Automated routing to appropriate support teams\n",
    "- Quick response suggestions\n",
    "- Better customer service analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a01fe",
   "metadata": {},
   "source": [
    "## Save Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd48113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ TF-IDF Vectorizer saved to: ../models\\tfidf_vectorizer.pkl\n",
      "âœ“ Logistic Regression Model saved to: ../models\\logistic_regression_model.pkl\n",
      "\n",
      "Both models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create a models directory if it doesn't exist\n",
    "models_dir = '../models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer.pkl')\n",
    "with open(vectorizer_path, 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "print(f\"âœ“ TF-IDF Vectorizer saved to: {vectorizer_path}\")\n",
    "\n",
    "# Save the Logistic Regression model\n",
    "model_path = os.path.join(models_dir, 'logistic_regression_model.pkl')\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(logistic_model, f)\n",
    "print(f\"âœ“ Logistic Regression Model saved to: {model_path}\")\n",
    "\n",
    "print(\"\\nBoth models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351891c",
   "metadata": {},
   "source": [
    "### Load Saved Models (for future use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to load the saved models later\n",
    "# Uncomment and run this code when you want to load the models\n",
    "\n",
    "# import pickle\n",
    "# \n",
    "# # Load TF-IDF Vectorizer\n",
    "# with open('../models/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "#     loaded_vectorizer = pickle.load(f)\n",
    "# \n",
    "# # Load Logistic Regression Model\n",
    "# with open('../models/logistic_regression_model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n",
    "# \n",
    "# print(\"Models loaded successfully!\")\n",
    "# \n",
    "# # Test with a sample query\n",
    "# test_text = \"I want to cancel my order\"\n",
    "# test_text_clean = test_text.lower().strip()\n",
    "# test_tfidf = loaded_vectorizer.transform([test_text_clean])\n",
    "# prediction = loaded_model.predict(test_tfidf)[0]\n",
    "# print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b07b54",
   "metadata": {},
   "source": [
    "## Intent Routing System\n",
    "\n",
    "Define routing rules to handle different intents efficiently based on complexity and sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0930a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Routing Buckets Defined:\n",
      "================================================================================\n",
      "\n",
      "BUCKET_A: Direct/FAQ/Database - No LLM needed\n",
      "Cost: Zero\n",
      "Intents (8): check_invoice, check_payment_methods, check_refund_policy...\n",
      "\n",
      "BUCKET_B: RAG + Small LLM - Procedural with context\n",
      "Cost: Low\n",
      "Intents (15): cancel_order, change_order, place_order...\n",
      "\n",
      "BUCKET_C: Escalation - Big LLM or Human agent\n",
      "Cost: High\n",
      "Intents (4): complaint, payment_issue, contact_customer_service...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define intent routing buckets\n",
    "# Each intent is categorized based on complexity, sensitivity, and required response type\n",
    "\n",
    "INTENT_ROUTING = {\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # BUCKET A: No LLM (Direct / FAQ / DB)\n",
    "    # - Deterministic responses\n",
    "    # - Policy-based answers\n",
    "    # - Fixed information\n",
    "    # - Zero LLM cost\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    'BUCKET_A': {\n",
    "        'description': 'Direct/FAQ/Database - No LLM needed',\n",
    "        'cost': 'Zero',\n",
    "        'intents': [\n",
    "            'check_invoice',              # Query database\n",
    "            'check_payment_methods',      # Static FAQ\n",
    "            'check_refund_policy',        # Policy document\n",
    "            'check_cancellation_fee',     # Policy document\n",
    "            'delivery_period',            # Static FAQ\n",
    "            'delivery_options',           # Static FAQ\n",
    "            'track_order',                # Database lookup\n",
    "            'track_refund',               # Database lookup\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # BUCKET B: RAG + Small LLM\n",
    "    # - Procedural queries\n",
    "    # - Needs contextual explanation\n",
    "    # - How-to instructions\n",
    "    # - May vary by user context\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    'BUCKET_B': {\n",
    "        'description': 'RAG + Small LLM - Procedural with context',\n",
    "        'cost': 'Low',\n",
    "        'intents': [\n",
    "            'cancel_order',               # Procedural with conditions\n",
    "            'change_order',               # Multi-step process\n",
    "            'place_order',                # Guided process\n",
    "            'get_invoice',                # Process + delivery\n",
    "            'get_refund',                 # Process explanation\n",
    "            'set_up_shipping_address',    # How-to guide\n",
    "            'change_shipping_address',    # Process with validation\n",
    "            'create_account',             # Step-by-step guide\n",
    "            'edit_account',               # Procedural guidance\n",
    "            'switch_account',             # Process explanation\n",
    "            'delete_account',             # Process + warnings\n",
    "            'recover_password',           # Security process\n",
    "            'registration_problems',      # Troubleshooting\n",
    "            'newsletter_subscription',    # Simple process\n",
    "            'review',                     # Guidance on leaving review\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # BUCKET C: Escalation (Big LLM / Human)\n",
    "    # - Emotional/sensitive issues\n",
    "    # - Financial disputes\n",
    "    # - Complex complaints\n",
    "    # - Legal/policy risks\n",
    "    # - Requires empathy and judgment\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    'BUCKET_C': {\n",
    "        'description': 'Escalation - Big LLM or Human agent',\n",
    "        'cost': 'High',\n",
    "        'intents': [\n",
    "            'complaint',                  # Emotional, needs empathy\n",
    "            'payment_issue',              # Financial dispute\n",
    "            'contact_customer_service',   # General escalation\n",
    "            'contact_human_agent',        # Explicit human request\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Intent Routing Buckets Defined:\")\n",
    "print(\"=\" * 80)\n",
    "for bucket_name, bucket_info in INTENT_ROUTING.items():\n",
    "    print(f\"\\n{bucket_name}: {bucket_info['description']}\")\n",
    "    print(f\"Cost: {bucket_info['cost']}\")\n",
    "    print(f\"Intents ({len(bucket_info['intents'])}): {', '.join(bucket_info['intents'][:3])}...\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48368c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse mapping created for fast lookup!\n",
      "Total intents mapped: 27\n",
      "\n",
      "âœ“ All intents from the model are mapped to buckets!\n"
     ]
    }
   ],
   "source": [
    "# Create reverse mapping for quick lookup\n",
    "intent_to_bucket = {}\n",
    "for bucket_name, bucket_info in INTENT_ROUTING.items():\n",
    "    for intent in bucket_info['intents']:\n",
    "        intent_to_bucket[intent] = {\n",
    "            'bucket': bucket_name,\n",
    "            'description': bucket_info['description'],\n",
    "            'cost': bucket_info['cost']\n",
    "        }\n",
    "\n",
    "print(\"Reverse mapping created for fast lookup!\")\n",
    "print(f\"Total intents mapped: {len(intent_to_bucket)}\")\n",
    "\n",
    "# Check for any unmapped intents from our model\n",
    "all_model_intents = set(logistic_model.classes_)\n",
    "mapped_intents = set(intent_to_bucket.keys())\n",
    "unmapped_intents = all_model_intents - mapped_intents\n",
    "\n",
    "if unmapped_intents:\n",
    "    print(f\"\\nâš  Warning: {len(unmapped_intents)} unmapped intents found:\")\n",
    "    for intent in unmapped_intents:\n",
    "        print(f\"  - {intent}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All intents from the model are mapped to buckets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aafee7",
   "metadata": {},
   "source": [
    "### Complete Message Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b0cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline functions created successfully!\n"
     ]
    }
   ],
   "source": [
    "def process_user_message(user_message, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Complete pipeline: User message â†’ Intent â†’ Routing decision\n",
    "    \n",
    "    Flow:\n",
    "    1. Clean text\n",
    "    2. TF-IDF vectorization\n",
    "    3. Logistic Regression prediction\n",
    "    4. Intent + confidence\n",
    "    5. Route to appropriate bucket\n",
    "    \n",
    "    Args:\n",
    "        user_message: Raw user input\n",
    "        confidence_threshold: Minimum confidence to trust prediction (default: 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with prediction, routing, and action plan\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Clean text\n",
    "    text_clean = re.sub(r'\\{\\{.*?\\}\\}', '', user_message)\n",
    "    text_clean = text_clean.lower().strip()\n",
    "    text_clean = re.sub(r'\\s+', ' ', text_clean)\n",
    "    \n",
    "    # STEP 2 & 3: TF-IDF + Logistic Regression\n",
    "    text_tfidf = tfidf_vectorizer.transform([text_clean])\n",
    "    predicted_intent = logistic_model.predict(text_tfidf)[0]\n",
    "    probabilities = logistic_model.predict_proba(text_tfidf)[0]\n",
    "    confidence = max(probabilities)\n",
    "    \n",
    "    # STEP 4: Get routing information\n",
    "    routing_info = intent_to_bucket.get(predicted_intent, {\n",
    "        'bucket': 'BUCKET_C',  # Default to escalation if unknown\n",
    "        'description': 'Unknown intent - escalate',\n",
    "        'cost': 'High'\n",
    "    })\n",
    "    \n",
    "    # STEP 5: Determine action based on bucket and confidence\n",
    "    if confidence < confidence_threshold:\n",
    "        action = \"LOW_CONFIDENCE_ESCALATE\"\n",
    "        bucket = \"BUCKET_C\"\n",
    "        reason = f\"Low confidence ({confidence:.2%}) - Escalate to human\"\n",
    "    else:\n",
    "        action = routing_info['bucket']\n",
    "        bucket = routing_info['bucket']\n",
    "        \n",
    "        if bucket == 'BUCKET_A':\n",
    "            reason = \"Direct database/FAQ lookup - No LLM needed\"\n",
    "        elif bucket == 'BUCKET_B':\n",
    "            reason = \"RAG + Small LLM for procedural response\"\n",
    "        else:  # BUCKET_C\n",
    "            reason = \"Escalate to Big LLM or Human agent\"\n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'user_message': user_message,\n",
    "        'cleaned_text': text_clean,\n",
    "        'predicted_intent': predicted_intent,\n",
    "        'confidence': confidence,\n",
    "        'bucket': bucket,\n",
    "        'action': action,\n",
    "        'reason': reason,\n",
    "        'cost_tier': routing_info['cost']\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def display_routing_decision(result):\n",
    "    \"\"\"Pretty print the routing decision\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"USER MESSAGE PROCESSING PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nğŸ“¨ Original Message: {result['user_message']}\")\n",
    "    print(f\"ğŸ§¹ Cleaned Text: {result['cleaned_text']}\")\n",
    "    print(f\"\\nğŸ¯ Predicted Intent: {result['predicted_intent']}\")\n",
    "    print(f\"ğŸ“Š Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"\\nğŸ—‚ï¸  Routing Bucket: {result['bucket']}\")\n",
    "    print(f\"ğŸ’° Cost Tier: {result['cost_tier']}\")\n",
    "    print(f\"âš¡ Action: {result['action']}\")\n",
    "    print(f\"ğŸ“ Reason: {result['reason']}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"Pipeline functions created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c205a3a7",
   "metadata": {},
   "source": [
    "### Test Complete Pipeline with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4017b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING COMPLETE PIPELINE WITH SAMPLE MESSAGES\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: Where is my invoice?\n",
      "ğŸ§¹ Cleaned Text: where is my invoice?\n",
      "\n",
      "ğŸ¯ Predicted Intent: get_invoice\n",
      "ğŸ“Š Confidence: 60.85%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_B\n",
      "ğŸ’° Cost Tier: Low\n",
      "âš¡ Action: BUCKET_B\n",
      "ğŸ“ Reason: RAG + Small LLM for procedural response\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: What payment methods do you accept?\n",
      "ğŸ§¹ Cleaned Text: what payment methods do you accept?\n",
      "\n",
      "ğŸ¯ Predicted Intent: check_payment_methods\n",
      "ğŸ“Š Confidence: 94.45%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_A\n",
      "ğŸ’° Cost Tier: Zero\n",
      "âš¡ Action: BUCKET_A\n",
      "ğŸ“ Reason: Direct database/FAQ lookup - No LLM needed\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: Track my order #12345\n",
      "ğŸ§¹ Cleaned Text: track my order #12345\n",
      "\n",
      "ğŸ¯ Predicted Intent: track_order\n",
      "ğŸ“Š Confidence: 84.89%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_A\n",
      "ğŸ’° Cost Tier: Zero\n",
      "âš¡ Action: BUCKET_A\n",
      "ğŸ“ Reason: Direct database/FAQ lookup - No LLM needed\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: How do I cancel my order?\n",
      "ğŸ§¹ Cleaned Text: how do i cancel my order?\n",
      "\n",
      "ğŸ¯ Predicted Intent: cancel_order\n",
      "ğŸ“Š Confidence: 99.35%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_B\n",
      "ğŸ’° Cost Tier: Low\n",
      "âš¡ Action: BUCKET_B\n",
      "ğŸ“ Reason: RAG + Small LLM for procedural response\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: I need to change my shipping address\n",
      "ğŸ§¹ Cleaned Text: i need to change my shipping address\n",
      "\n",
      "ğŸ¯ Predicted Intent: change_shipping_address\n",
      "ğŸ“Š Confidence: 91.06%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_B\n",
      "ğŸ’° Cost Tier: Low\n",
      "âš¡ Action: BUCKET_B\n",
      "ğŸ“ Reason: RAG + Small LLM for procedural response\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: Can you help me reset my password?\n",
      "ğŸ§¹ Cleaned Text: can you help me reset my password?\n",
      "\n",
      "ğŸ¯ Predicted Intent: recover_password\n",
      "ğŸ“Š Confidence: 88.56%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_B\n",
      "ğŸ’° Cost Tier: Low\n",
      "âš¡ Action: BUCKET_B\n",
      "ğŸ“ Reason: RAG + Small LLM for procedural response\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: I'm very upset about my order, this is unacceptable!\n",
      "ğŸ§¹ Cleaned Text: i'm very upset about my order, this is unacceptable!\n",
      "\n",
      "ğŸ¯ Predicted Intent: delivery_options\n",
      "ğŸ“Š Confidence: 46.25%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_C\n",
      "ğŸ’° Cost Tier: Zero\n",
      "âš¡ Action: LOW_CONFIDENCE_ESCALATE\n",
      "ğŸ“ Reason: Low confidence (46.25%) - Escalate to human\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: My payment was charged twice, I want a refund NOW!\n",
      "ğŸ§¹ Cleaned Text: my payment was charged twice, i want a refund now!\n",
      "\n",
      "ğŸ¯ Predicted Intent: payment_issue\n",
      "ğŸ“Š Confidence: 28.76%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_C\n",
      "ğŸ’° Cost Tier: High\n",
      "âš¡ Action: LOW_CONFIDENCE_ESCALATE\n",
      "ğŸ“ Reason: Low confidence (28.76%) - Escalate to human\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "USER MESSAGE PROCESSING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¨ Original Message: I need to speak with a human agent immediately\n",
      "ğŸ§¹ Cleaned Text: i need to speak with a human agent immediately\n",
      "\n",
      "ğŸ¯ Predicted Intent: contact_human_agent\n",
      "ğŸ“Š Confidence: 97.15%\n",
      "\n",
      "ğŸ—‚ï¸  Routing Bucket: BUCKET_C\n",
      "ğŸ’° Cost Tier: High\n",
      "âš¡ Action: BUCKET_C\n",
      "ğŸ“ Reason: Escalate to Big LLM or Human agent\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test messages representing each bucket\n",
    "test_messages = [\n",
    "    # BUCKET A examples (Direct/FAQ/DB)\n",
    "    \"Where is my invoice?\",\n",
    "    \"What payment methods do you accept?\",\n",
    "    \"Track my order #12345\",\n",
    "    \n",
    "    # BUCKET B examples (RAG + Small LLM)\n",
    "    \"How do I cancel my order?\",\n",
    "    \"I need to change my shipping address\",\n",
    "    \"Can you help me reset my password?\",\n",
    "    \n",
    "    # BUCKET C examples (Escalation)\n",
    "    \"I'm very upset about my order, this is unacceptable!\",\n",
    "    \"My payment was charged twice, I want a refund NOW!\",\n",
    "    \"I need to speak with a human agent immediately\",\n",
    "]\n",
    "\n",
    "print(\"TESTING COMPLETE PIPELINE WITH SAMPLE MESSAGES\\n\")\n",
    "\n",
    "for message in test_messages:\n",
    "    result = process_user_message(message)\n",
    "    display_routing_decision(result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6c6a6",
   "metadata": {},
   "source": [
    "### Routing Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f785af1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTENT ROUTING DISTRIBUTION\n",
      "================================================================================\n",
      "Total Intents: 27\n",
      "\n",
      "BUCKET_A\n",
      "  Description: Direct/FAQ/Database - No LLM needed\n",
      "  Intents: 8 (29.6%)\n",
      "  Cost Tier: Zero\n",
      "\n",
      "BUCKET_B\n",
      "  Description: RAG + Small LLM - Procedural with context\n",
      "  Intents: 15 (55.6%)\n",
      "  Cost Tier: Low\n",
      "\n",
      "BUCKET_C\n",
      "  Description: Escalation - Big LLM or Human agent\n",
      "  Intents: 4 (14.8%)\n",
      "  Cost Tier: High\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š COST OPTIMIZATION STRATEGY:\n",
      "  â€¢ 29.6% queries â†’ Zero LLM cost (Direct/DB/FAQ)\n",
      "  â€¢ 55.6% queries â†’ Low cost (Small LLM + RAG)\n",
      "  â€¢ 14.8% queries â†’ High cost (Big LLM/Human)\n",
      "\n",
      "ğŸ’¡ Expected Cost Savings: ~70% reduction by avoiding LLM for simple queries!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze distribution of intents across buckets\n",
    "bucket_distribution = {}\n",
    "for bucket_name, bucket_info in INTENT_ROUTING.items():\n",
    "    bucket_distribution[bucket_name] = {\n",
    "        'count': len(bucket_info['intents']),\n",
    "        'percentage': len(bucket_info['intents']) / 27 * 100,\n",
    "        'cost': bucket_info['cost'],\n",
    "        'description': bucket_info['description']\n",
    "    }\n",
    "\n",
    "print(\"INTENT ROUTING DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Intents: 27\\n\")\n",
    "\n",
    "for bucket, info in bucket_distribution.items():\n",
    "    print(f\"{bucket}\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Intents: {info['count']} ({info['percentage']:.1f}%)\")\n",
    "    print(f\"  Cost Tier: {info['cost']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nğŸ“Š COST OPTIMIZATION STRATEGY:\")\n",
    "print(f\"  â€¢ {bucket_distribution['BUCKET_A']['percentage']:.1f}% queries â†’ Zero LLM cost (Direct/DB/FAQ)\")\n",
    "print(f\"  â€¢ {bucket_distribution['BUCKET_B']['percentage']:.1f}% queries â†’ Low cost (Small LLM + RAG)\")\n",
    "print(f\"  â€¢ {bucket_distribution['BUCKET_C']['percentage']:.1f}% queries â†’ High cost (Big LLM/Human)\")\n",
    "print(\"\\nğŸ’¡ Expected Cost Savings: ~70% reduction by avoiding LLM for simple queries!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a046d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Routing configuration saved to: ../models\\routing_config.json\n",
      "\n",
      "Now you have:\n",
      "  1. tfidf_vectorizer.pkl - Text vectorization\n",
      "  2. logistic_regression_model.pkl - Intent prediction\n",
      "  3. routing_config.json - Intent routing rules\n",
      "\n",
      "Ready to deploy! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# Save routing configuration\n",
    "import json\n",
    "\n",
    "routing_config = {\n",
    "    'intent_routing': INTENT_ROUTING,\n",
    "    'intent_to_bucket_mapping': intent_to_bucket,\n",
    "    'confidence_threshold': 0.5\n",
    "}\n",
    "\n",
    "config_path = os.path.join(models_dir, 'routing_config.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(routing_config, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Routing configuration saved to: {config_path}\")\n",
    "print(\"\\nNow you have:\")\n",
    "print(\"  1. tfidf_vectorizer.pkl - Text vectorization\")\n",
    "print(\"  2. logistic_regression_model.pkl - Intent prediction\")\n",
    "print(\"  3. routing_config.json - Intent routing rules\")\n",
    "print(\"\\nReady to deploy! ğŸš€\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
